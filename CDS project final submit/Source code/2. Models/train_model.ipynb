{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem: \n",
    "***Get insights from the dataset of INX Future Inc., to find-out why the employees' Performance Index is not as per expectations and what can be done to improve the current situation.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: \n",
    "- In this notebook we use the Processed Data that we have transformed from Raw Data and built a Machine Learning Model.\n",
    "- Here we use 'INX_Future_Inc_Employee_Performance_Processed_Data.xlsx\n",
    "\n",
    "**Steps in Train_Model**\n",
    "\n",
    "Step 1 : Import the libraries\n",
    "\n",
    "Step 2 : Import the Processed data-set\n",
    "\n",
    "Step 3 : Split the Processed data-set\n",
    "\n",
    "Step 4 : Try Different Machine Learning Model\n",
    "\n",
    "Step 5 : Select the Model,Hypertune it and Train it\n",
    "\n",
    "Step 6 : Export the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1 : Import the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd #andas is for data manipulation and analysis. \n",
    "\n",
    "# Import Different Models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import joblib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2 : Import the Processed data-set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmpNumber</th>\n",
       "      <th>SalaryHike_NewCat</th>\n",
       "      <th>Env_Satis_NewCat</th>\n",
       "      <th>EmpEnvironmentSatisfaction</th>\n",
       "      <th>EmpLastSalaryHikePercent</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>EmpWorkLifeBalance</th>\n",
       "      <th>ExperienceYearsInCurrentRole</th>\n",
       "      <th>EmpJobRole</th>\n",
       "      <th>EmpHourlyRate</th>\n",
       "      <th>EmpDepartment_Development</th>\n",
       "      <th>Age</th>\n",
       "      <th>PerformanceRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1001000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E1001006</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E1001007</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E1001009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1001010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EmpNumber  SalaryHike_NewCat  Env_Satis_NewCat  EmpEnvironmentSatisfaction  \\\n",
       "0  E1001000                  1                 2                           4   \n",
       "1  E1001006                  1                 2                           4   \n",
       "2  E1001007                  2                 2                           4   \n",
       "3  E1001009                  1                 1                           2   \n",
       "4  E1001010                  1                 1                           1   \n",
       "\n",
       "   EmpLastSalaryHikePercent  YearsSinceLastPromotion  EmpWorkLifeBalance  \\\n",
       "0                        12                        0                   2   \n",
       "1                        12                        1                   3   \n",
       "2                        21                        1                   3   \n",
       "3                        15                       12                   2   \n",
       "4                        14                        2                   3   \n",
       "\n",
       "   ExperienceYearsInCurrentRole  EmpJobRole  EmpHourlyRate  \\\n",
       "0                             7          13             55   \n",
       "1                             7          13             42   \n",
       "2                            13          13             48   \n",
       "3                             6           8             73   \n",
       "4                             2          13             84   \n",
       "\n",
       "   EmpDepartment_Development  Age  PerformanceRating  \n",
       "0                          0   32                  3  \n",
       "1                          0   47                  3  \n",
       "2                          0   40                  4  \n",
       "3                          0   41                  3  \n",
       "4                          0   60                  3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.height', 500)\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "df = pd.read_excel('INX_Future_Inc_Employee_Performance_Processed010_Data.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3 : Split the Processed data-set into X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save EmpNumber for later\n",
    "Emp_Number = df.EmpNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"EmpNumber\",axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test splits\n",
    "target_name = 'PerformanceRating'\n",
    "X = df.drop('PerformanceRating', axis=1)\n",
    "\n",
    "\n",
    "y=df[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 11)\n",
      "(240, 11)\n",
      "(960,)\n",
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=0, stratify=None)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4 : Try Different Machine Learning Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "model1 = xgboost.XGBClassifier()\n",
    "classifiers.append(model1)\n",
    "model2 = svm.SVC()\n",
    "classifiers.append(model2)\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "model4 = RandomForestClassifier()\n",
    "classifiers.append(model4)\n",
    "model5 = KNeighborsClassifier()\n",
    "classifiers.append(model5)\n",
    "model6 =GaussianNB()\n",
    "classifiers.append(model6)\n",
    "model7 =MLPClassifier(alpha=1, max_iter=1000)\n",
    "classifiers.append(model7)\n",
    "model8 = AdaBoostClassifier()\n",
    "classifiers.append(model8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) is 0.9625\n",
      "Accuracy of SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) is 0.7458333333333333\n",
      "Accuracy of DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') is 0.9166666666666666\n",
      "Accuracy of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) is 0.9708333333333333\n",
      "Accuracy of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform') is 0.7541666666666667\n",
      "Accuracy of GaussianNB(priors=None, var_smoothing=1e-09) is 0.8416666666666667\n",
      "Accuracy of MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) is 0.8708333333333333\n",
      "Accuracy of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None) is 0.6625\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89166667 0.925      0.98333333 0.93333333 0.99166667 0.98333333\n",
      " 0.94166667 0.89166667 0.90833333 0.88333333]\n",
      "Accuracy: 0.93 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# Using 10 fold Cross-Validation to train our RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model4 = RandomForestClassifier()\n",
    "\n",
    "#The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its \n",
    "#best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. \n",
    "scores = cross_val_score(model4 ,X, y, cv=10,scoring='f1_micro')\n",
    "print(scores)\n",
    "#The mean score and the 95% confidence interval of the score estimate are hence given by:\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgboost.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89166667 0.94166667 0.98333333 0.925      0.99166667 0.975\n",
      " 0.91666667 0.9        0.93333333 0.89166667]\n",
      "Accuracy: 0.94 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "# Using 10 fold Cross-Validation to train our  XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model1 = xgboost.XGBClassifier()\n",
    "\n",
    "#The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its \n",
    "#best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. \n",
    "scores = cross_val_score(model1 ,X, y, cv=10,scoring='f1_micro')\n",
    "print(scores)\n",
    "#The mean score and the 95% confidence interval of the score estimate are hence given by:\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations:\n",
    " After Using 10 fold Cross-Validation\n",
    "- Accuracy of RandomForestClassifier() is after 0.93 (+/- 0.08)\n",
    "- Accuracy of XGBClassifier() is after 0.94 (+/- 0.07)\n",
    "\n",
    "\n",
    "Hence, we select XGBClassifier() as our final Machine Learning Model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Select the Model and Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ht = xgboost.XGBClassifier(base_score=0.75, booster='gbtree', \n",
    "                          learning_rate=0.02,  \n",
    "                               max_depth=5,\n",
    "                            min_child_weight=3,# can be 1,10,100 etc it parctically works\n",
    "                             n_estimators=300, \n",
    "                               objective='multi:softprob',\n",
    "                               random_state=0,\n",
    "                               reg_alpha=0, \n",
    "                               reg_lambda=1,  \n",
    "                               colsample_bylevel=1,\n",
    "                            colsample_bynode=1,\n",
    "                             colsample_bytree=1 # it works better than other two,\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 10 fold Cross-Validation to train our Logistic Regression Model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#model = LogisticRegression(multi_class='multinomial',solver='newton-cg',class_weight = None)\n",
    "\n",
    "#The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its \n",
    "#best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. \n",
    "scores = cross_val_score(xgb_ht ,X, y, cv=10,scoring='f1_micro')\n",
    "print(scores)\n",
    "#The mean score and the 95% confidence interval of the score estimate are hence given by:\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing cross-validation to train/test split\n",
    "\n",
    "Advantages of cross-validation:\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "Advantages of train/test split:\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.75, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.02, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=3, missing=None, n_estimators=300, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ht.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Export the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xbgboost_Classifier_INX_performace_predict.pkl']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(xgb_ht, 'Xbgboost_Classifier_INX_performace_predict.pkl')       \n",
    "#joblib.dump to serialize an object hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
